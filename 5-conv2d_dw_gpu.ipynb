{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eGZIh3o1xch"
      },
      "source": [
        "# Depthwise-seperable 2D Convolution on GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD2GHA5WVSow"
      },
      "source": [
        "## 1. Set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HnmfRsiBVSow",
        "outputId": "67f0b075-b0be-49a9-a0cc-81081884808c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rR5CmYuCVSox"
      },
      "outputs": [],
      "source": [
        "# Make sure your token is stored in a txt file at the location below.\n",
        "# This way there is no risk that you will push it to your repo\n",
        "# Never share your token with anyone, it is basically your github password!\n",
        "with open('/content/gdrive/MyDrive/ece5545/token.txt') as f:\n",
        "    token = f.readline().strip()\n",
        "# Use another file to store your github username\n",
        "with open('/content/gdrive/MyDrive/ece5545/git_username.txt') as f:\n",
        "    handle = f.readline().strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AZHBLuQfVSox",
        "outputId": "7c6c25da-42ba-4ffa-c618-ee122de05a3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/gdrive/MyDrive/ece5545’: File exists\n",
            "/content/gdrive/MyDrive/ece5545\n",
            "fatal: destination path 'a3-kpan02' already exists and is not an empty directory.\n",
            "/content/gdrive/MyDrive/ece5545/a3-kpan02\n",
            "M\tsrc/ops.py\n",
            "Already on 'main'\n",
            "Your branch is up to date with 'origin/main'.\n",
            "Already up to date.\n",
            "/content/gdrive/MyDrive/ece5545\n"
          ]
        }
      ],
      "source": [
        "# Clone your github repo\n",
        "YOUR_TOKEN = token\n",
        "YOUR_HANDLE = handle\n",
        "BRANCH = \"main\"\n",
        "\n",
        "%mkdir /content/gdrive/MyDrive/ece5545\n",
        "%cd /content/gdrive/MyDrive/ece5545\n",
        "!git clone https://{YOUR_TOKEN}@github.com/ML-HW-SYS/a3-{YOUR_HANDLE}.git\n",
        "%cd /content/gdrive/MyDrive/ece5545/a3-{YOUR_HANDLE}\n",
        "!git checkout {BRANCH}\n",
        "!git pull\n",
        "%cd /content/gdrive/MyDrive/ece5545\n",
        "\n",
        "PROJECT_ROOT = f\"/content/gdrive/MyDrive/ece5545/a3-{YOUR_HANDLE}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QfJNPVatVSox"
      },
      "outputs": [],
      "source": [
        "# This extension reloads all imports before running each cell\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "v7Bztq-VVSoy",
        "outputId": "45a88935-6778-4b19-b39f-ce5c9cb6c2cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1-conv1d_cpu.ipynb   4-gemm_gpu.ipynb\t    README.md\n",
            "2-conv1d_gpu.ipynb   5-conv2d_dw_gpu.ipynb  src\n",
            "3-conv1d_fpga.ipynb  leaderboard_id.txt     tests\n"
          ]
        }
      ],
      "source": [
        "!ls {PROJECT_ROOT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EghxXWHSVyZR"
      },
      "source": [
        "## 2 Install TVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Phf10Wb1VxoB",
        "outputId": "279d4948-5a9c-404d-a714-d3c30cf5fef7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.24.3 in /usr/local/lib/python3.11/dist-packages (1.24.3)\n",
            "Looking in links: https://tlcpack.ai/wheels\n",
            "Requirement already satisfied: tlcpack-nightly-cu102 in /usr/local/lib/python3.11/dist-packages (0.15.dev118+g51bdaec6e)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (25.3.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (3.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (4.4.2)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (0.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (1.24.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (5.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (1.14.1)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (6.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (4.13.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy==1.24.3\n",
        "!pip install tlcpack-nightly-cu102 -f https://tlcpack.ai/wheels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1dTOTtqVSoy"
      },
      "source": [
        "## 3. Implement `make_dwsp_conv2d_gpu_scheduler` function in `src.ops`\n",
        "\n",
        "In that function, you are required to implemented 2D convolution and use TVM to optimize it.\n",
        "Please use zero padding and unit stride.\n",
        "You can assume kernel size to be an odd number.\n",
        "The padding will equals to kernel size minus ones.\n",
        "In this case, the output image will preserve the input image dimension.\n",
        "\n",
        "The `make_dwsp_conv2d_gpu_scheduler` takes following arguments:\n",
        "1. Batch size $B$;\n",
        "2. Input channel size $C$;\n",
        "3. Input image height $H$;\n",
        "4. Input image width $W$;\n",
        "5. Output number of channels $O$;\n",
        "6. Kernel size $K$\n",
        "\n",
        "You should return both the TVM scheduler and the TVM opterator for\n",
        "1. Input tensor $x$ with size (B, C, H, W)\n",
        "2. Input kernel weight $y$ with size (O, 1, K, K)\n",
        "3. Output $out$ with size (B, O, H, W)\n",
        "\n",
        "The scheduler should be able to used to build a function with signature $func(x, y, out)$.\n",
        "Please see the following cells the usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-rbp2mmTVSoz",
        "outputId": "ed1f19c4-7587-4f88-bbb4-2411d84ff8a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2DConv TVM: 0.023808 ms\n"
          ]
        }
      ],
      "source": [
        "import tvm\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import sys\n",
        "# Adding assignment 3 to the system path\n",
        "# Make sure this matches your git directory\n",
        "sys.path.insert(0, PROJECT_ROOT)\n",
        "from src.ops import make_dwsp_conv2d_gpu_scheduler\n",
        "\n",
        "B = 3\n",
        "C = 4\n",
        "H = 16\n",
        "W = 32\n",
        "K = 7\n",
        "dtype = 'float32'\n",
        "a_np = np.random.rand(B, C, H, W).astype(dtype)\n",
        "w_np = np.random.rand(C, 1, K, K).astype(dtype)\n",
        "\n",
        "s, inp, ker, out = make_dwsp_conv2d_gpu_scheduler(B, C, H, W, K)\n",
        "func = tvm.build(s, [inp, ker, out], \"cuda\")\n",
        "\n",
        "dev = tvm.cuda(0)\n",
        "a = tvm.nd.array(a_np, dev)\n",
        "w = tvm.nd.array(w_np, dev)\n",
        "b = tvm.nd.array(np.zeros((B, C, H, W), dtype), dev)\n",
        "func(a, w, b)\n",
        "evaluator = func.time_evaluator(func.entry_name, dev, number=1, repeat =1)\n",
        "\n",
        "# print(\"Output:\", b)\n",
        "print(f\"2DConv TVM: %f ms\" % (evaluator(a, w, b).mean * 1e3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mtM-xfNHVSoz",
        "outputId": "18a3629e-4962-4585-985a-1b0be37f0351",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((3, 4, 16, 32), \"float32\"), W: T.Buffer((4, 1, 7, 7), \"float32\"), out: T.Buffer((3, 4, 16, 32), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        blockIdx_z = T.launch_thread(\"blockIdx.z\", 3)\n",
            "        blockIdx_y = T.launch_thread(\"blockIdx.y\", 1)\n",
            "        blockIdx_x = T.launch_thread(\"blockIdx.x\", 2)\n",
            "        threadIdx_z = T.launch_thread(\"threadIdx.z\", 4)\n",
            "        threadIdx_y = T.launch_thread(\"threadIdx.y\", 16)\n",
            "        threadIdx_x = T.launch_thread(\"threadIdx.x\", 16)\n",
            "        out_1 = T.Buffer((6144,), data=out.data)\n",
            "        out_1[blockIdx_z * 2048 + threadIdx_z * 512 + threadIdx_y * 32 + blockIdx_x * 16 + threadIdx_x] = T.float32(0)\n",
            "        for r_h, r_w in T.grid(7, 7):\n",
            "            A_1 = T.Buffer((6144,), data=A.data)\n",
            "            W_1 = T.Buffer((196,), data=W.data)\n",
            "            out_1[blockIdx_z * 2048 + threadIdx_z * 512 + threadIdx_y * 32 + blockIdx_x * 16 + threadIdx_x] = out_1[blockIdx_z * 2048 + threadIdx_z * 512 + threadIdx_y * 32 + blockIdx_x * 16 + threadIdx_x] + T.if_then_else(3 <= threadIdx_y + r_h and threadIdx_y + r_h < 19 and 3 <= blockIdx_x * 16 + threadIdx_x + r_w and blockIdx_x * 16 + threadIdx_x + r_w < 35, A_1[blockIdx_z * 2048 + threadIdx_z * 512 + threadIdx_y * 32 + r_h * 32 + blockIdx_x * 16 + threadIdx_x + r_w - 99], T.float32(0)) * W_1[threadIdx_z * 49 + r_h * 7 + r_w]\n"
          ]
        }
      ],
      "source": [
        "print(tvm.lower(s, [inp, ker, out], simple_mode=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QE2DD12GVSoz",
        "scrolled": false,
        "outputId": "6f4d4248-1c42-4cfc-d17a-a833ad4a7f65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/ece5545/a3-kpan02\n",
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.11.12, pytest-8.3.5, pluggy-1.5.0\n",
            "rootdir: /content/gdrive/MyDrive/ece5545/a3-kpan02\n",
            "plugins: typeguard-4.4.2, anyio-4.9.0, langsmith-0.3.24\n",
            "collected 1357 items                                                           \u001b[0m\n",
            "\n",
            "tests/test_dwsp_2dconv_gpu.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [  3%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [  8%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 13%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 19%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 24%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 29%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 34%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 40%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 45%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 50%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 56%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 61%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 66%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 72%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 77%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 82%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 87%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 93%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 98%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31m                                                      [100%]\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m____________________________ test1_speed_torch[30] _____________________________\u001b[0m\n",
            "\n",
            "execution_number = 30\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.shape), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 30x speed-up failed: TVM Time: 2.09998e-03s TorchTime: 5.78171e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.0020999810003559105 * 30.0) <= 0.0578170870003305\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[31m\u001b[1m____________________________ test1_speed_torch[50] _____________________________\u001b[0m\n",
            "\n",
            "execution_number = 50\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.shape), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 50x speed-up failed: TVM Time: 2.19833e-03s TorchTime: 3.81725e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.002198333000706043 * 50.0) <= 0.03817248300038045\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[31m\u001b[1m____________________________ test1_speed_torch[60] _____________________________\u001b[0m\n",
            "\n",
            "execution_number = 60\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.shape), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 60x speed-up failed: TVM Time: 1.25560e-03s TorchTime: 5.81529e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.0012555969997265493 * 60.0) <= 0.058152895000603166\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[31m\u001b[1m____________________________ test1_speed_torch[70] _____________________________\u001b[0m\n",
            "\n",
            "execution_number = 70\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.shape), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 70x speed-up failed: TVM Time: 1.30087e-03s TorchTime: 3.65817e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.0013008739997530938 * 70.0) <= 0.03658171400002175\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[31m\u001b[1m____________________________ test1_speed_torch[80] _____________________________\u001b[0m\n",
            "\n",
            "execution_number = 80\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.shape), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 80x speed-up failed: TVM Time: 1.31211e-03s TorchTime: 3.81801e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.0013121100000716979 * 80.0) <= 0.038180091999493015\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[31m\u001b[1m____________________________ test1_speed_torch[90] _____________________________\u001b[0m\n",
            "\n",
            "execution_number = 90\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.shape), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 90x speed-up failed: TVM Time: 1.27277e-03s TorchTime: 3.49255e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.0012727690000247094 * 90.0) <= 0.03492546199959179\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[31m\u001b[1m____________________________ test1_speed_torch[100] ____________________________\u001b[0m\n",
            "\n",
            "execution_number = 100\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[33m'\u001b[39;49;00m\u001b[33mexecution_number\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[94m2\u001b[39;49;00m, \u001b[94m4\u001b[39;49;00m, \u001b[94m8\u001b[39;49;00m, \u001b[94m10\u001b[39;49;00m, \u001b[94m20\u001b[39;49;00m, \u001b[94m30\u001b[39;49;00m, \u001b[94m40\u001b[39;49;00m, \u001b[94m50\u001b[39;49;00m, \u001b[94m60\u001b[39;49;00m, \u001b[94m70\u001b[39;49;00m, \u001b[94m80\u001b[39;49;00m, \u001b[94m90\u001b[39;49;00m, \u001b[94m100\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest1_speed_torch\u001b[39;49;00m(execution_number):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Define dimension\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        B, C, H, W, K = \u001b[94m1\u001b[39;49;00m, \u001b[94m5\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        n_repeat = \u001b[94m100\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Create random test data\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        np.random.seed(seed=\u001b[94m1024\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        a_np = np.random.rand(B, C, H, W).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        w_np = np.random.rand(C, \u001b[94m1\u001b[39;49;00m, K, K).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Torch input\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        a_torch = torch.tensor(a_np).float()\u001b[90m\u001b[39;49;00m\n",
            "        w_torch = torch.tensor(w_np).float()\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the torch implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtorch_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "        time_torch = timeit.timeit(torch_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "        b_torch = ans_torch(a_torch, w_torch)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m# Time the optimized implementation\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        func = make_func(B, C, H, W, K)\u001b[90m\u001b[39;49;00m\n",
            "        a = tvm.nd.array(a_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        w = tvm.nd.array(w_np, dev)\u001b[90m\u001b[39;49;00m\n",
            "        b = tvm.nd.array(np.zeros(\u001b[96mtuple\u001b[39;49;00m(b_torch.shape), dtype=\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), dev)\u001b[90m\u001b[39;49;00m\n",
            "        func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mdef\u001b[39;49;00m \u001b[92mtvm_time\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
            "            func(a, w, b)\u001b[90m\u001b[39;49;00m\n",
            "        time_tvm = timeit.timeit(tvm_time, number=n_repeat)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        opt_folds = \u001b[96mfloat\u001b[39;49;00m(execution_number)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m time_tvm * opt_folds <= time_torch, \\\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33mx speed-up failed: TVM Time: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms TorchTime: \u001b[39;49;00m\u001b[33m%.5e\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \\\n",
            "            % (execution_number, time_tvm, time_torch, )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: 100x speed-up failed: TVM Time: 1.18967e-03s TorchTime: 3.66748e-02s\u001b[0m\n",
            "\u001b[1m\u001b[31mE       assert (0.0011896659998456016 * 100.0) <= 0.036674763000519306\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_dwsp_2dconv_gpu.py\u001b[0m:97: AssertionError\n",
            "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[30]\u001b[0m - AssertionError: 30x speed-up failed: TVM Time: 2.09998e-03s TorchTime: 5.78...\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[50]\u001b[0m - AssertionError: 50x speed-up failed: TVM Time: 2.19833e-03s TorchTime: 3.81...\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[60]\u001b[0m - AssertionError: 60x speed-up failed: TVM Time: 1.25560e-03s TorchTime: 5.81...\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[70]\u001b[0m - AssertionError: 70x speed-up failed: TVM Time: 1.30087e-03s TorchTime: 3.65...\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[80]\u001b[0m - AssertionError: 80x speed-up failed: TVM Time: 1.31211e-03s TorchTime: 3.81...\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[90]\u001b[0m - AssertionError: 90x speed-up failed: TVM Time: 1.27277e-03s TorchTime: 3.49...\n",
            "\u001b[31mFAILED\u001b[0m tests/test_dwsp_2dconv_gpu.py::\u001b[1mtest1_speed_torch[100]\u001b[0m - AssertionError: 100x speed-up failed: TVM Time: 1.18967e-03s TorchTime: 3.6...\n",
            "\u001b[31m================== \u001b[31m\u001b[1m7 failed\u001b[0m, \u001b[32m1350 passed\u001b[0m\u001b[31m in 859.63s (0:14:19)\u001b[0m\u001b[31m ==================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%cd {PROJECT_ROOT}\n",
        "!python -m pytest tests/test_dwsp_2dconv_gpu.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "5-conv2d_dw_gpu.ipynb",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}