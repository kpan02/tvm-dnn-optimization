{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eGZIh3o1xch"
      },
      "source": [
        "# GEMM on GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IcE4c-V5Psg"
      },
      "source": [
        "## 1. Set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bMbgGWP75Psg",
        "outputId": "35fa3f41-18be-420f-fd54-3d97623afa79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "REpyYw1o5Psi"
      },
      "outputs": [],
      "source": [
        "# Make sure your token is stored in a txt file at the location below.\n",
        "# This way there is no risk that you will push it to your repo\n",
        "# Never share your token with anyone, it is basically your github password!\n",
        "with open('/content/gdrive/MyDrive/ece5545/token.txt') as f:\n",
        "    token = f.readline().strip()\n",
        "# Use another file to store your github username\n",
        "with open('/content/gdrive/MyDrive/ece5545/git_username.txt') as f:\n",
        "    handle = f.readline().strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xmVrYXr05Psi",
        "outputId": "e06cc36a-34e2-4b9c-cb37-ec11faa939e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/gdrive/MyDrive/ece5545’: File exists\n",
            "/content/gdrive/MyDrive/ece5545\n",
            "fatal: destination path 'a3-kpan02' already exists and is not an empty directory.\n",
            "/content/gdrive/MyDrive/ece5545/a3-kpan02\n",
            "M\tsrc/ops.py\n",
            "Already on 'main'\n",
            "Your branch is up to date with 'origin/main'.\n",
            "Already up to date.\n",
            "/content/gdrive/MyDrive/ece5545\n"
          ]
        }
      ],
      "source": [
        "# Clone your github repo\n",
        "YOUR_TOKEN = token\n",
        "YOUR_HANDLE = handle\n",
        "BRANCH = \"main\"\n",
        "\n",
        "%mkdir /content/gdrive/MyDrive/ece5545\n",
        "%cd /content/gdrive/MyDrive/ece5545\n",
        "!git clone https://{YOUR_TOKEN}@github.com/ML-HW-SYS/a3-{YOUR_HANDLE}.git\n",
        "%cd /content/gdrive/MyDrive/ece5545/a3-{YOUR_HANDLE}\n",
        "!git checkout {BRANCH}\n",
        "!git pull\n",
        "%cd /content/gdrive/MyDrive/ece5545\n",
        "\n",
        "PROJECT_ROOT = f\"/content/gdrive/MyDrive/ece5545/a3-{YOUR_HANDLE}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ll4LScr_5Psi"
      },
      "outputs": [],
      "source": [
        "# This extension reloads all imports before running each cell\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WdiSdTlu5Psj",
        "outputId": "a15f8bba-3747-43d3-a016-433fd8c57287",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1-conv1d_cpu.ipynb   4-gemm_gpu.ipynb\t    README.md\n",
            "2-conv1d_gpu.ipynb   5-conv2d_dw_gpu.ipynb  src\n",
            "3-conv1d_fpga.ipynb  leaderboard_id.txt     tests\n"
          ]
        }
      ],
      "source": [
        "!ls {PROJECT_ROOT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJDlW3_V5uX8"
      },
      "source": [
        "## 2. Install TVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VkqX6TEG5tz7",
        "outputId": "8d5a272e-9502-466e-bf9b-442c4b90e123",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.24.3 in /usr/local/lib/python3.11/dist-packages (1.24.3)\n",
            "Looking in links: https://tlcpack.ai/wheels\n",
            "Requirement already satisfied: tlcpack-nightly-cu102 in /usr/local/lib/python3.11/dist-packages (0.15.dev118+g51bdaec6e)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (25.3.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (3.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (4.4.2)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (0.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (1.24.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (5.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (1.14.1)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (6.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (4.13.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy==1.24.3\n",
        "!pip install tlcpack-nightly-cu102 -f https://tlcpack.ai/wheels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16GZ_We05Psj"
      },
      "source": [
        "## 3. Check the implementation of `make_gemm_gpu_scheduler` function in `src.ops`\n",
        "\n",
        "The function implements General Matrix Multiply (GEMM) on GPU. You should use TVM to optimize it.\n",
        "\n",
        "Let $A \\in \\mathbb{R}^{m \\times k}$, $W \\in \\mathbb{R}^{k \\times n}$, and $B \\in \\mathbb{R}^{m \\times n}$, then\n",
        "$$\n",
        "B = A \\times W\n",
        "$$\n",
        "Please see the numpy matmul function for more detail: [link](https://numpy.org/doc/stable/reference/generated/numpy.matmul.html).\n",
        "\n",
        "The `make_gemm_gpu_scheduler` takes $m$, $k$, and $n$. The first matrix is $m \\times k$, the second matrix is $k \\times n$, and the output matrix is $m \\times n$.\n",
        "\n",
        "The function returns both the TVM scheduler and the TVM opterator for\n",
        "1. Input $a$\n",
        "2. Input $w$\n",
        "3. Output $b$\n",
        "\n",
        "The scheduler should be able to used to build a function with signature $func(a, w, b)$.\n",
        "Please see the following cells for usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2nIPEBHF5Psj",
        "outputId": "7460c3c0-fecb-46fd-d231-cf9952402cf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: [[511.21603 523.69086 533.4453  ... 505.56244 516.326   522.1519 ]\n",
            " [504.8399  523.59705 527.8334  ... 500.84293 512.91907 509.86575]\n",
            " [499.38998 512.8939  512.59033 ... 486.7307  491.46466 508.764  ]\n",
            " ...\n",
            " [514.9759  528.45703 534.9043  ... 508.16986 520.47095 525.9487 ]\n",
            " [505.64557 527.23987 523.86597 ... 495.59018 509.95844 515.9603 ]\n",
            " [508.211   522.7613  529.2311  ... 504.02762 514.0861  518.62836]]\n",
            "Output: [[511.21637 523.6911  533.4453  ... 505.5621  516.32605 522.152  ]\n",
            " [504.84006 523.59717 527.834   ... 500.84293 512.9185  509.86615]\n",
            " [499.38956 512.89355 512.5899  ... 486.7312  491.46457 508.76407]\n",
            " ...\n",
            " [514.9762  528.45715 534.9042  ... 508.1693  520.4713  525.949  ]\n",
            " [505.6456  527.2397  523.86584 ... 495.5904  509.95786 515.96045]\n",
            " [508.2114  522.76166 529.23145 ... 504.02737 514.0859  518.62805]]\n",
            "GEMM TVM: 24.762304 ms\n"
          ]
        }
      ],
      "source": [
        "import tvm\n",
        "import numpy as np\n",
        "import sys\n",
        "# Adding assignment 3 to the system path\n",
        "# Make sure this matches your git directory\n",
        "sys.path.insert(0, PROJECT_ROOT)\n",
        "from src.ops import make_gemm_gpu_scheduler\n",
        "\n",
        "M = 1024\n",
        "N = 512\n",
        "K = 2048\n",
        "dtype = 'float32'\n",
        "a_np = np.random.rand(M, K).astype(dtype)\n",
        "w_np = np.random.rand(K, N).astype(dtype)\n",
        "b_np = np.matmul(a_np, w_np)\n",
        "\n",
        "s, A, W, B = make_gemm_gpu_scheduler(M, K, N)\n",
        "func = tvm.build(s, [A, W, B], \"cuda\")\n",
        "\n",
        "dev = tvm.cuda(0)\n",
        "a = tvm.nd.array(a_np, dev)\n",
        "w = tvm.nd.array(w_np, dev)\n",
        "b = tvm.nd.array(np.zeros((M, N), dtype), dev)\n",
        "func(a, w, b)\n",
        "evaluator = func.time_evaluator(func.entry_name, dev, number=1, repeat =1)\n",
        "\n",
        "\n",
        "print(\"Answer:\", b_np)\n",
        "print(\"Output:\", b)\n",
        "print(f\"GEMM TVM: %f ms\" % (evaluator(a, w, b).mean * 1e3))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "import numpy as np\n",
        "numpy_timer = timeit.Timer(lambda: np.matmul(a_np, w_np))\n",
        "numpy_time = numpy_timer.timeit(number=1) * 1000\n",
        "print(f\"Numpy Reference Runtime: {numpy_time:.6f} ms\")"
      ],
      "metadata": {
        "id": "VPoqyn0pmINU",
        "outputId": "23a6189b-d69d-4f01-bccc-d47fd24d34ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numpy Reference Runtime: 52.949851 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bjnf_oPi5Psk",
        "scrolled": true,
        "outputId": "7a562e8c-7177-4a4b-e249-1ccce70342e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((1024, 2048), \"float32\"), B: T.Buffer((2048, 512), \"float32\"), C: T.Buffer((1024, 512), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        blockIdx_x = T.launch_thread(\"blockIdx.x\", 64)\n",
            "        A_shared = T.allocate([128], \"float32\", \"shared\")\n",
            "        B_shared = T.allocate([128], \"float32\", \"shared\")\n",
            "        blockIdx_y = T.launch_thread(\"blockIdx.y\", 32)\n",
            "        threadIdx_x = T.env_thread(\"threadIdx.x\")\n",
            "        threadIdx_y = T.env_thread(\"threadIdx.y\")\n",
            "        C_1 = T.Buffer((524288,), data=C.data)\n",
            "        with T.launch_thread(threadIdx_x, 16):\n",
            "            T.launch_thread(threadIdx_y, 16)\n",
            "            C_1[blockIdx_x * 8192 + threadIdx_x * 512 + blockIdx_y * 16 + threadIdx_y] = T.float32(0)\n",
            "        for k_outer in range(256):\n",
            "            threadIdx_x_1 = T.env_thread(\"threadIdx.x\")\n",
            "            A_shared_1 = T.Buffer((128,), data=A_shared, scope=\"shared\")\n",
            "            for ax0_ax1_fused_outer in range(8):\n",
            "                T.launch_thread(threadIdx_x_1, 16)\n",
            "                A_1 = T.Buffer((2097152,), data=A.data)\n",
            "                A_shared_1[ax0_ax1_fused_outer * 16 + threadIdx_x_1] = A_1[blockIdx_x * 32768 + ax0_ax1_fused_outer * 4096 + threadIdx_x_1 // 8 * 2048 + k_outer * 8 + threadIdx_x_1 % 8]\n",
            "            B_shared_1 = T.Buffer((128,), data=B_shared, scope=\"shared\")\n",
            "            for ax0_ax1_fused_outer in range(8):\n",
            "                T.launch_thread(threadIdx_x_1, 16)\n",
            "                B_1 = T.Buffer((1048576,), data=B.data)\n",
            "                B_shared_1[ax0_ax1_fused_outer * 16 + threadIdx_x_1] = B_1[k_outer * 4096 + ax0_ax1_fused_outer * 512 + blockIdx_y * 16 + threadIdx_x_1]\n",
            "            T.launch_thread(threadIdx_x, 16)\n",
            "            T.launch_thread(threadIdx_y, 16)\n",
            "            C_1[blockIdx_x * 8192 + threadIdx_x * 512 + blockIdx_y * 16 + threadIdx_y] = C_1[blockIdx_x * 8192 + threadIdx_x * 512 + blockIdx_y * 16 + threadIdx_y] + A_shared_1[threadIdx_x * 8] * B_shared_1[threadIdx_y]\n",
            "            C_1[blockIdx_x * 8192 + threadIdx_x * 512 + blockIdx_y * 16 + threadIdx_y] = C_1[blockIdx_x * 8192 + threadIdx_x * 512 + blockIdx_y * 16 + threadIdx_y] + A_shared_1[threadIdx_x * 8 + 1] * B_shared_1[threadIdx_y + 16]\n",
            "            C_1[blockIdx_x * 8192 + threadIdx_x * 512 + blockIdx_y * 16 + threadIdx_y] = C_1[blockIdx_x * 8192 + threadIdx_x * 512 + blockIdx_y * 16 + threadIdx_y] + A_shared_1[threadIdx_x * 8 + 2] * B_shared_1[threadIdx_y + 32]\n",
            "            C_1[blockIdx_x * 8192 + threadIdx_x * 512 + blockIdx_y * 16 + threadIdx_y] = C_1[blockIdx_x * 8192 + threadIdx_x * 512 + blockIdx_y * 16 + threadIdx_y] + A_shared_1[threadIdx_x * 8 + 3] * B_shared_1[threadIdx_y + 48]\n",
            "            C_1[blockIdx_x * 8192 + threadIdx_x * 512 + blockIdx_y * 16 + threadIdx_y] = C_1[blockIdx_x * 8192 + threadIdx_x * 512 + blockIdx_y * 16 + threadIdx_y] + A_shared_1[threadIdx_x * 8 + 4] * B_shared_1[threadIdx_y + 64]\n",
            "            C_1[blockIdx_x * 8192 + threadIdx_x * 512 + blockIdx_y * 16 + threadIdx_y] = C_1[blockIdx_x * 8192 + threadIdx_x * 512 + blockIdx_y * 16 + threadIdx_y] + A_shared_1[threadIdx_x * 8 + 5] * B_shared_1[threadIdx_y + 80]\n",
            "            C_1[blockIdx_x * 8192 + threadIdx_x * 512 + blockIdx_y * 16 + threadIdx_y] = C_1[blockIdx_x * 8192 + threadIdx_x * 512 + blockIdx_y * 16 + threadIdx_y] + A_shared_1[threadIdx_x * 8 + 6] * B_shared_1[threadIdx_y + 96]\n",
            "            C_1[blockIdx_x * 8192 + threadIdx_x * 512 + blockIdx_y * 16 + threadIdx_y] = C_1[blockIdx_x * 8192 + threadIdx_x * 512 + blockIdx_y * 16 + threadIdx_y] + A_shared_1[threadIdx_x * 8 + 7] * B_shared_1[threadIdx_y + 112]\n"
          ]
        }
      ],
      "source": [
        "print(tvm.lower(s, [A, W, B], simple_mode=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VQiasz7n5Psk",
        "scrolled": false,
        "outputId": "5d29df5f-1885-4e80-e3bc-a96f6c67e8cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/ece5545/a3-kpan02\n",
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.11.12, pytest-8.3.5, pluggy-1.5.0\n",
            "rootdir: /content/gdrive/MyDrive/ece5545/a3-kpan02\n",
            "plugins: typeguard-4.4.2, anyio-4.9.0, langsmith-0.3.24\n",
            "collected 20 items                                                             \u001b[0m\n",
            "\n",
            "tests/test_gemm_gpu.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                              [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m============================= \u001b[32m\u001b[1m20 passed\u001b[0m\u001b[32m in 23.38s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%cd {PROJECT_ROOT}\n",
        "!python -m pytest tests/test_gemm_gpu.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "4-gemm_gpu.ipynb",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}